// "Flat" Variational Ladder Auto-Encoder (VLAE)

// - could share more params in model by ignoring level in net names
// - should memoize getState in guide to avoid redundant computation


// Settings

var numLevels = 3;  // number of latent levels in hierarchy

var dataDim = 1;  // length of vector for each datum
var dataSize = [dataDim, 1]

var noiseDim = 3;
var noiseSize = [noiseDim, 1];

var latentDim = 5;
var latentSize = [latentDim, 1];

var guideLatentDim = 7;


// Helpers

var call = function(f, a, b, c, d, e) {
  return f(a, b, c, d, e);
};


// Model with guide

var mlp = function(name, dims) {
  return stack([
    // sigmoid,
    // affine('mlp-' + name + '-l2', { in: dims.in, out: dims.out }),
    tanh,
    affine('mlp-' + name + '-l1', { in: dims.in, out: dims.out })
  ]);
};

var finalNet = function(state) {  // f_0
  var net = mlp('final', { in: latentDim, out: dataDim*2 });
  return net(state);  
};

var combineNet = function(state, level, noise) {  // f_l
  var net = mlp('combine-' + level, { in: latentDim * 2, out: latentDim });  // u_l
  return net(concat([state, initNet(level, noise)]));
};

var initNet = function(level, noise) {  // f_L, v_l
  var net = mlp('init-' + level, { in: noiseDim, out: latentDim });
  return net(noise);
};

var noiseDist = function(level) {  //  z_l ~ noiseDist(l)
  return DiagCovGaussian({
    mu: zeros(noiseSize),
    sigma: ones(noiseSize)
  });
};

var dataDist = function(finalState) {  // r
  return DiagCovGaussian({  // use more expressive family here?
    mu: T.range(finalState, 0, dataDim),
    sigma: softplus(T.range(finalState, dataDim, dataDim*2))
  })
};

var initGuide = function(datum) {

  var muNet = function(level, state) {  // mu_l
    var net = mlp('guide-mu-' + level, { in: guideLatentDim, out: noiseDim });
    return net(state);
  };

  var sigmaNet = function(level, state) {  // sigma_l
    var net = mlp('guide-sigma-' + level, { in: guideLatentDim, out: noiseDim });
    return net(state);
  };

  var liftNet = function(level, state) {  // g_l
    var inputDim = (level === 1) ? dataDim : guideLatentDim;
    var net = mlp('guide-lift-' + level, { in: inputDim, out: guideLatentDim });
    return net(state);
  };
  
  var getState = function(level) {  // return state at given level
    if (level === 0) {
      return datum;
    } else {
      var prevGuideState = getState(level-1);
      var state = liftNet(level, prevGuideState);
      return state;
    }
  };

  var noiseGuideDist = function(level) {
    var state = getState(level);
    return DiagCovGaussian({
      mu: muNet(level, state),
      sigma: softplus(sigmaNet(level, state))
    });
  };

  globalStore.noiseGuideDist = noiseGuideDist;
  
};

var recur = function(level, state) {
  if (level === 0) {
    return dataDist(finalNet(state));
  } else {
    var noise = sample(noiseDist(level), { guide() {
      return call(globalStore.noiseGuideDist, level);
    }});  // z_l
    var nextState = combineNet(state, level, noise);  // z_tidle_l
    return recur(level-1, nextState);
  }
};

var model = function(level, target) {
  guide(function() {
    initGuide(target);
  });
  var noise = sample(noiseDist(level), { guide() {
    return call(globalStore.noiseGuideDist, level);
  }});  // z_L
  var state = initNet(level, noise);  // z_tilde_L
  return recur(level-1, state);
};


// Training and sampling

var data = [
  ones(dataSize),
  zeros(dataSize)  
];

Optimize({
  model() {    
    mapData({ data }, function(datum) {
      var dist = model(numLevels, datum);
      observe(dist, T.reshape(datum, [dataDim]));
    });
  },
  steps: 10000
});

var showSupport = function(dist) {
  console.log(JSON.stringify(_.flatten(dist.support()).sort(), null, 2));
};

// Model posterior with conditioning on data point
var conditionedDist = Infer({
  model() {
    var dist = model(numLevels, data[0]);
    return T.toScalars(sample(dist, { guide() { return dist; }}));
  },
  method: 'forward',
  guide: true,
  samples: 50
});
showSupport(conditionedDist);

// Show trained model distribution without conditioning on data point
var unconditionedDist = Infer({
  model() {
    var dist = model(numLevels);
    return T.toScalars(sample(dist, { guide() { return dist; }}));
  },
  method: 'forward',
  guide: false,
  samples: 50
});
showSupport(unconditionedDist);